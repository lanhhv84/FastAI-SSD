{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uyu14X_XN1vk"
   },
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XCglfIsSipHK"
   },
   "source": [
    "#### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G2Ww-sV-ipHL"
   },
   "outputs": [],
   "source": [
    "# from pathlib import PosixPath\n",
    "\n",
    "# root = PosixPath('/mnt/188f6bc0-7ce9-4833-a30f-60f6ee8c4aef/Project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZvIX8rKipHO"
   },
   "source": [
    "#### Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uf4mrrUfwR0P"
   },
   "outputs": [],
   "source": [
    "# !pip install detection-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "8DFFwsG5kIBC",
    "outputId": "fa03a947-52a3-4224-f9b4-f9590ae64846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "from pathlib import PosixPath\n",
    "\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "root = PosixPath('/content/drive/My Drive/DS/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2s93YT7R2fkv"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(str(root/'lib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ZcWngLEAvsbo",
    "outputId": "e0a7063f-9ef3-4cc0-9939-64e93b70b616"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from xml.dom import minidom\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.nn.modules.upsampling import Upsample\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.pyplot  as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from os.path import isfile\n",
    "from joblib import dump, load\n",
    "from functools import partial\n",
    "from fastai.train import clip_grad\n",
    "from torchvision import transforms\n",
    "# from detection_utils.boxes import box_overlaps\n",
    "from ssd import SSD\n",
    "from fastai.vision import *\n",
    "import imagesize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cupSfywX6rsd"
   },
   "source": [
    "### VOC read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EIkGAEFsipHR"
   },
   "outputs": [],
   "source": [
    "path = root/'yolo'\n",
    "voc_path = path/'voc/VOCdevkit/VOC2012/'\n",
    "images_path = voc_path/'JPEGImages'\n",
    "anno_path = voc_path/'Annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZrIu0Cpy6q6b"
   },
   "outputs": [],
   "source": [
    "images_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACLgigeI2-Wc"
   },
   "outputs": [],
   "source": [
    "# for anno in anno_path.iterdir():\n",
    "    \n",
    "#     boxes = []\n",
    "#     classes = []\n",
    "#     with minidom.parse(str(anno)) as xmldoc:\n",
    "#         filename = xmldoc.getElementsByTagName('filename')[0].childNodes[0].data\n",
    "#         bndboxes = xmldoc.getElementsByTagName('bndbox')\n",
    "#         names = xmldoc.getElementsByTagName('name')\n",
    "#         for i in range(len(bndboxes)):\n",
    "#             bndbox = bndboxes[i]\n",
    "#             xmin = bndbox.getElementsByTagName('xmin')[0].childNodes[0].data\n",
    "#             xmax = bndbox.getElementsByTagName('xmax')[0].childNodes[0].data\n",
    "#             ymin = bndbox.getElementsByTagName('ymin')[0].childNodes[0].data\n",
    "#             ymax = bndbox.getElementsByTagName('ymax')[0].childNodes[0].data\n",
    "#             box = [ymin, xmin, ymax, xmax]\n",
    "#             boxes.append(box)\n",
    "#             name = names[i].childNodes[0].data\n",
    "#             classes.append(name)\n",
    "#         images_data[filename] = [boxes, classes]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDjm2q9f-jr5"
   },
   "outputs": [],
   "source": [
    "# dict_data = images_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jCSyxTT-BWDy"
   },
   "outputs": [],
   "source": [
    "# classes = list(set([i for x in images_data.values() for i in x[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S15_rpk_Qu3Z"
   },
   "outputs": [],
   "source": [
    "# classes_dict = {x: index for index, x in enumerate(classes)}\n",
    "# classes_dict['background'] = len(classes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4F6OoDSqMKeH"
   },
   "outputs": [],
   "source": [
    "# index_dict = {val: key for key, val in classes_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fb5Co4h-R2pz"
   },
   "outputs": [],
   "source": [
    "# index_dict[len(index_dict)] = 'background'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXr4sj9LQ4TM"
   },
   "outputs": [],
   "source": [
    "# for key in dict_data:\n",
    "#     val = dict_data[key]\n",
    "# #     val[1] = [index_dict.get(x, classes_dict.get(x, index_dict.get(x))) for x in val[1]]\n",
    "#     val[0] = [[float(v) for v in box] for box in val[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LhQDfKp1RJWJ"
   },
   "outputs": [],
   "source": [
    "# classes_dict['background'] = len(classes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gw6UJbXORHDO"
   },
   "outputs": [],
   "source": [
    "# dump(dict_data, voc_path/'data.pkl')\n",
    "\n",
    "# dump(classes_dict, voc_path/'dict.pkl')\n",
    "\n",
    "dict_data = load(voc_path/'data.pkl')\n",
    "classes_dict = load(voc_path/'dict.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_ffY1Bx-n--"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eofa1xIeRTPV"
   },
   "outputs": [],
   "source": [
    "NBOXES = 3\n",
    "N_CLASSES = len(classes_dict)\n",
    "FEATURES = NBOXES*(5 + N_CLASSES)\n",
    "\n",
    "TX = 0\n",
    "TY = 1\n",
    "TW = 2\n",
    "TH = 3\n",
    "CONF = 4\n",
    "bs = 16\n",
    "\n",
    "\n",
    "IMAGE_GRID = 26\n",
    "IMAGE_SIZE = 300# 416 ## \n",
    "# label = [bouding box, (5), 26, 26]\n",
    "BOX_SIZDE = IMAGE_SIZE / IMAGE_GRID\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LOSS_REDUCTION = 'sum'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jzz4wHH3In0"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ww10ctrjXk9H"
   },
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5PXYxaUipIM"
   },
   "outputs": [],
   "source": [
    "def roundboxes(boxes):\n",
    "    return [[[b[1], b[0], b[1] + b[3], b[0] + b[2]] for b in boxes], ['face']*len(boxes)]\n",
    "\n",
    "def emptyboxes():\n",
    "    return [[[0, 0, 0, 0]], ['background']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lcw39dVBY6lG"
   },
   "outputs": [],
   "source": [
    "def label_func(x):\n",
    "    x = PosixPath(x).name\n",
    "    return dict_data.get(x, emptyboxes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "darrnZsZoLXF"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({'name': list(dict_data.keys())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ozJ-WNqcipIZ"
   },
   "outputs": [],
   "source": [
    "data = ObjectItemList.from_df(train_df, path=images_path).split_by_rand_pct()\n",
    "pad_collate = partial(bb_pad_collate, pad_idx='background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVtW_0vwTEn6"
   },
   "outputs": [],
   "source": [
    "data = data.label_from_func(label_func)\\\n",
    ".transform(get_transforms(), size=IMAGE_SIZE, tfm_y=True)\\\n",
    ".databunch(bs=bs, val_bs=bs*2, collate_fn=bb_pad_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUI0h5oLanQb"
   },
   "outputs": [],
   "source": [
    "data.show_batch(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RL9Nbc8DhsQf"
   },
   "outputs": [],
   "source": [
    "# data.save(voc_path/'data.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YN_0osgN87Lm"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBgMyOf9u4mg"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qQ9C4bohsQj"
   },
   "outputs": [],
   "source": [
    "batch[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QSYFBvQym_U"
   },
   "outputs": [],
   "source": [
    "batch_sample = 2\n",
    "image = batch[0][batch_sample]\n",
    "boxes = batch[1][0][batch_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKiUBi_UUWCo"
   },
   "outputs": [],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIIgPlM5zI4p"
   },
   "outputs": [],
   "source": [
    "boxes = np.array([[-0.6910, -1.0000,  0.8046,  0.8126], [-0.0524, -0.5271,  0.4435, -0.3555], [-0.7457, -1.0000,  0.3988, -0.3220]])\n",
    "boxes = (boxes + 1)*(IMAGE_SIZE/2)\n",
    "boxes = [[x, y, w - x, h - y] for [y, x, h, w] in boxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJzm0p3P5Aoc"
   },
   "outputs": [],
   "source": [
    "np_image = image.permute(1, 2, 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IEDqaMCd7Bu0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Create a Rectangle patch\n",
    "for cord in boxes:\n",
    "    [x, y, w, h] = [int(round(a)) for a in cord]\n",
    "    print((x,y), (x+w,y+h))\n",
    "    cv2.rectangle((np_image*255).astype('int32'), (x,y), (x+w,y+h), (0,255,0), 10)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(np_image)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ER-WlKUX0RYb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Create a Rectangle patch\n",
    "for cord in boxes:\n",
    "    [x, y, w, h] = [int(round(a)) for a in cord]\n",
    "    print((x,y), (x+w,y+h))\n",
    "    np_image = cv2.rectangle((np_image*255).astype('int32'), (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(np_image)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6h2YwTgNbBto"
   },
   "source": [
    "### Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9ZkTQ9Jaxdu"
   },
   "outputs": [],
   "source": [
    "from ssd import MobileNetSSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGRc6H4aho0y"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "net = MobileNetSSD(N_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dv7xp8pIhsQ0"
   },
   "source": [
    "- Forward to calculate $(g_{c_x}, g_{c_y}, g_w, g_h)$\n",
    "- Identify corresponding prior $(\\hat{c}_x, \\hat{c}_y, \\hat{w}, \\hat{h})$\n",
    "- Calculate Predicted box \n",
    "    - $c_x = g_{c_x}*\\hat{w} + \\hat{c}_x$\n",
    "    - $c_y = g_{c_y}*\\hat{h} + \\hat{c}_y$\n",
    "    - $w = e^{g_{w}}*\\hat{w}$\n",
    "    - $h = e^{g_{h}}*\\hat{h}$\n",
    "- Calculate IoU\n",
    "- Match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y50E9oeshsQ1"
   },
   "source": [
    "- Create overlapping table between predicted and ground truth (8732*number of ground truth object)\n",
    "- Match each priors with greatest overlap\n",
    "- Categorize as positive and negative match\n",
    "- Calculate loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dpcusqCmhsQ2"
   },
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KE9oyw6xhsQ2"
   },
   "outputs": [],
   "source": [
    "eps = 1e-3\n",
    "\n",
    "\n",
    "def iou_table(x, truth, bs, nboxes, maxlen):\n",
    "    truth_xA = truth[:, 0, :] - truth[:, 2, :] / 2\n",
    "    truth_yA = truth[:, 1, :] - truth[:, 3, :] / 2\n",
    "    truth_xB = truth[:, 0, :] + truth[:, 2, :] / 2\n",
    "    truth_yB = truth[:, 1, :] + truth[:, 3, :] / 2\n",
    "    nb = truth_xA.shape[-1]\n",
    "\n",
    "    \n",
    "    pred_xA = x[:, 0, :] - x[:, 2, :]/2\n",
    "    pred_yA = x[:, 1, :] - x[:, 3, :]/2\n",
    "    pred_xB = x[:, 0, :] + x[:, 2, :]/2\n",
    "    pred_yB = x[:, 1, :] + x[:, 3, :]/2\n",
    "\n",
    "    xA = torch.max(pred_xA.contiguous().view(-1)[:, None], truth_xA[:, None, :].expand(*pred_xA.shape, nb).contiguous().view(-1, nb)).view(bs, -1, nb)\n",
    "    yA = torch.max(pred_yA.contiguous().view(-1)[:, None], truth_yA[:, None, :].expand(*pred_yA.shape, nb).contiguous().view(-1, nb)).view(bs, -1, nb)\n",
    "    xB = torch.min(pred_xB.contiguous().view(-1)[:, None], truth_xB[:, None, :].expand(*pred_xB.shape, nb).contiguous().view(-1, nb)).view(bs, -1, nb)\n",
    "    yB = torch.min(pred_yB.contiguous().view(-1)[:, None], truth_yB[:, None, :].expand(*pred_yB.shape, nb).contiguous().view(-1, nb)).view(bs, -1, nb)\n",
    "\n",
    "\n",
    "\n",
    "    interX = torch.clamp(xB - xA + 1/IMAGE_SIZE, min=0)\n",
    "    interY = torch.clamp(yB - yA + 1/IMAGE_SIZE, min=0)\n",
    "    interArea =  interX*interY\n",
    "\n",
    "    boxAArea = (pred_xB - pred_xA + 1/IMAGE_SIZE) * (pred_yB - pred_yA + 1/IMAGE_SIZE)\n",
    "    boxBArea = (truth_xB - truth_xB + 1/IMAGE_SIZE) * (truth_yB - truth_yA + 1/IMAGE_SIZE)\n",
    "    bs = boxAArea.shape[0]\n",
    "    nb = boxAArea.shape[1]\n",
    "    ml = boxBArea.shape[1]\n",
    "    boxAArea = boxAArea[..., None].expand(bs, nb, ml)\n",
    "    boxBArea = boxBArea[:, None, :].expand(bs, nb, ml)\n",
    "    return interArea / torch.clamp(boxAArea + boxBArea - interArea, min=eps) # [bs, 8732, maxlen]\n",
    "\n",
    "\n",
    "\n",
    "def ssd_loss(out, truth_loc, truth_conf, smoothl1, cre, iou_thres=0.6):\n",
    "    loc, conf = out\n",
    "    assert len(loc) == 6\n",
    "    assert len(conf) == 6\n",
    "    assert len(loc[0].shape) == 4 \n",
    "    bs = truth_loc.shape[0]\n",
    "    maxlen = truth_loc.shape[1]\n",
    "    truth = truth_loc.permute(0, 2, 1) # (bs, 4, maxlen)\n",
    "    # offset (calculate center)\n",
    "    truth = (truth + 1)*(IMAGE_SIZE/2)\n",
    "    truth[:, 0, :], truth[:, 1 ,:] = truth[:, 1 ,:], truth[:, 0 ,:]\n",
    "    truth[:, 2, :], truth[:, 3, :] = truth[:, 3, :] - truth[:, 0, :], truth[:, 2, :] - truth[:, 1 ,:]\n",
    "    truth[:, 0, :], truth[:, 1 ,:] = truth[:, 0, :] + 0.5*truth[:, 2, :], truth[:, 1 ,:] + 0.5*truth[:, 3, :]\n",
    "    \n",
    "    \n",
    "    truth = truth/IMAGE_SIZE\n",
    "    \n",
    "    \n",
    "    for i in range(len(loc)):\n",
    "        assert torch.sum(torch.isnan(loc[i])) == 0, \"loc is NaN\"\n",
    "        loc[i] = loc[i].reshape(bs, -1, 4, loc[i].shape[-1], loc[i].shape[-1])\n",
    "        conf[i] = conf[i].reshape(bs, -1, N_CLASSES, loc[i].shape[-1], loc[i].shape[-1])\n",
    "        \n",
    "    \"\"\"\n",
    "        loc:\n",
    "            - (4, 4, 38, 38)\n",
    "            - (6, 4, 19, 19)\n",
    "            - (6, 4, 10, 10)\n",
    "            - (6, 4, 5, 5)\n",
    "            - (4, 4, 3, 3)\n",
    "            - (4, 4, 1, 1)\n",
    "            \n",
    "        conf:\n",
    "            - (4, n_classes, 38, 38)\n",
    "            - (6, n_classes, 19, 19)\n",
    "            - (6, n_classes, 10, 10)\n",
    "            - (6, n_classes, 5, 5)\n",
    "            - (4, n_classes, 3, 3)\n",
    "            - (4, n_classes, 1, 1)\n",
    "        truth_loc: (bs, maxlen, 4)\n",
    "        truth_conf: (bs, maxlen)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ratios4 = [1, 2, 0.5, 1]\n",
    "    ratios6 = [1, 2, 0.5, 3, 1/3, 1]\n",
    "    \n",
    "    ratios_map = [ ratios4, ratios6, ratios6, ratios6, ratios4, ratios4]\n",
    "    scales = [0.1, 0.2, 0.375, 0.55, 0.725, 0.9]\n",
    "    \n",
    "    pred = []\n",
    "    priors = []\n",
    "    \n",
    "    for index in range(len(loc)):\n",
    "        prior = torch.zeros_like(loc[index]) # bs, -1, 4, loc[i].shape[-1], loc[i].shape[-1]\n",
    "        # calculate prior (cx, cy)\n",
    "        for row in range(prior.shape[-1]):\n",
    "            for col in range(prior.shape[-1]):\n",
    "                prior[..., 0, row, col] = (0.5 + row) / prior.shape[-1] # Prior cx\n",
    "                prior[..., 1, row, col] = (0.5 + col) / prior.shape[-1] # prior cy\n",
    "        # calculate prior (w, h)\n",
    "        ratios = ratios_map[index]\n",
    "        scale = scales[index]\n",
    "        for i in range(len(ratios)):\n",
    "            r = ratios[i]\n",
    "            if i == len(ratios) - 1:\n",
    "                scale = scale*1.5\n",
    "            w = scale*np.sqrt(r)\n",
    "            h = scale/np.sqrt(r)\n",
    "            # w\n",
    "            prior[..., i, 2, :, :]  = w/prior.shape[-1]\n",
    "            prior[..., i, 3, :, :] = h/prior.shape[-1]\n",
    "        # done prior\n",
    "        # cx\n",
    "        assert torch.sum(torch.isnan(prior)) == 0, \"prior is NaN\"\n",
    "        pred_box = torch.zeros_like(loc[index])\n",
    "        pred_box[...,0,:,:] = loc[index][...,0,:,:]*prior[...,2,:,:] + prior[...,0,:,:]\n",
    "        pred_box[...,1,:,:] = loc[index][...,1,:,:]*prior[...,3,:,:] + prior[...,1,:,:]\n",
    "        pred_box[...,2,:,:] = torch.exp(loc[index][...,2,:,:])*prior[...,2,:,:]\n",
    "        pred_box[...,3,:,:] = torch.exp(loc[index][...,3,:,:])*prior[...,3,:,:]\n",
    "        priors.append(prior)\n",
    "        pred_box = pred_box.permute(0, 2, 1, 3, 4).contiguous().view(bs, 4, -1)\n",
    "        pred_box = torch.clamp(pred_box, min=0, max=1)\n",
    "        assert torch.sum(torch.isnan(pred_box)) == 0, \"Pred is NaN\"\n",
    "        pred.append(pred_box)\n",
    "    \n",
    "    pred = torch.cat(pred, dim=2) # (bs, 4, 8732)\n",
    "    assert list(pred.shape) == [bs, 4, 8732]\n",
    "    \n",
    "    assert list(truth.shape) == [bs, 4, maxlen]\n",
    "    # IoU\n",
    "    ious = iou_table(pred, truth=truth, bs=bs, nboxes=pred.shape[-1], maxlen=maxlen)\n",
    "    pconf = torch.cat([c.permute(0, 1, 3, 4, 2).contiguous().view(bs, -1, N_CLASSES) for c in conf], dim=1)\n",
    "    assert list(pconf.shape) == [bs, 8732, N_CLASSES]\n",
    "    max_ious, max_match = torch.max(ious, dim=2)\n",
    "    positive_match = max_ious > iou_thres # (bs, 8732)\n",
    "    assert list(positive_match.shape) == [bs, 8732]\n",
    "    pos_pred = pred.permute(0, 2, 1)[positive_match] # (total_match in batch, 4)\n",
    "    # done\n",
    "    # 443 -> 4, 4, 3, 8732\n",
    "    tr = truth[..., None].expand(*truth.shape, 8732).permute(0, 3, 2, 1) # 4, 8732, 3, 4\n",
    "    assert list(tr.shape) == [bs, 8732, maxlen, 4]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    truth_mask = torch.zeros_like(ious).byte().view(-1, maxlen) # (bs, 8732, maxlen)\n",
    "    truth_mask.scatter_(1, max_match.view(-1)[:, None], 1.)\n",
    "    truth_mask = truth_mask.view(bs, -1, maxlen)\n",
    "    \n",
    "    assert torch.sum(truth_mask).item() == 8732*bs, \"Total number of item is {}\".format(torch.sum(truth_mask).item())\n",
    "    \n",
    "    # pass\n",
    "    truth_mask = positive_match[..., None]*truth_mask\n",
    "    tr = tr[truth_mask]\n",
    "    \n",
    "    \n",
    "    assert list(tr.shape) == list(pos_pred.shape)\n",
    "    loc_loss = smoothl1(pos_pred, tr)\n",
    "    # confidence loss\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    assert list(pconf.shape) == [bs, 8732, N_CLASSES]\n",
    "    \n",
    "    \n",
    "    \n",
    "    priors = torch.cat([c.permute(0, 1, 3, 4, 2).contiguous().view(bs, -1, 4) for c in priors], dim=1)\n",
    "    assert list(priors.shape) == [bs, 8732, 4]\n",
    "    priors = priors.permute(0, 2, 1)\n",
    "    truth_ious = iou_table(priors, truth=truth, bs=bs, nboxes=pred.shape[-1], maxlen=maxlen)\n",
    "\n",
    "    max_iou, max_index = torch.max(truth_ious, dim=-1)# [bs, 8732], [bs, 8732]\n",
    "    # index: (bs, 8732) value (bs, 8732, maxlen)\n",
    "    truth_conf = truth_conf[:, None, :].expand(bs, 8732, maxlen) # (bs, 8732, maxlen)\n",
    "    assert list(truth_conf.shape) == [bs, 8732, maxlen]\n",
    "    tcof = truth_conf.gather(2, max_index[..., None].to(device))\n",
    "    tcof[max_iou < iou_thres] = 0\n",
    "    assert list(tcof.shape) == [bs, 8732, 1], \"Got shape {}\".format(list(tcof.shape))\n",
    "    \"\"\"\n",
    "    Use truth_ious as a mask\n",
    "    \"\"\"\n",
    "    \n",
    "    tcof = tcof.view(bs, -1)\n",
    "    \n",
    "    npos = torch.clamp(torch.sum(tcof > 0), min=1e-3)\n",
    "    nneg = 3*npos\n",
    "    \n",
    "    pos_index = tcof > 0\n",
    "    neg_index = tcof == 0\n",
    "    if npos > eps:\n",
    "        conf_pos_loss = cre(pconf[pos_index].view(-1, N_CLASSES), tcof[pos_index].view(-1))\n",
    "    else:\n",
    "        conf_pos_loss = 0\n",
    "    if nneg >= 1:\n",
    "        \n",
    "        p = pconf[neg_index].view(-1, N_CLASSES)\n",
    "        t = tcof[neg_index].view(-1, 1)\n",
    "        \n",
    "        maxp = torch.max(p, dim=1)[0]\n",
    "        \n",
    "        max_error = torch.topk(maxp, int(nneg.item()), dim=0)[1]\n",
    "        p = p[max_error, :]\n",
    "        t = t[max_error, :]\n",
    "        \n",
    "        conf_neg_loss = cre(p, t.view(-1))\n",
    "    else:\n",
    "        conf_neg_loss = 0\n",
    "    \n",
    "    conf_loss = conf_pos_loss + conf_neg_loss\n",
    "    \n",
    "    return (loc_loss/torch.clamp(torch.sum(truth_mask), min=eps) + conf_loss/npos) / bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxUUxUT0hsQ5"
   },
   "outputs": [],
   "source": [
    "loss = partial(ssd_loss, smoothl1=nn.SmoothL1Loss(reduction='sum'), cre=nn.CrossEntropyLoss(reduction='sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CvoO2ojZhsQ8"
   },
   "outputs": [],
   "source": [
    "opt = partial(torch.optim.SGD, lr=1e-3, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Epaf3e0ds4hH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcdY86hPq6DR"
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, net, loss_func=loss, opt_func=opt)\n",
    "clip_grad(learn, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c41lL0fkjOXe"
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    learn.fit(1, lr=1e-3, wd=0.0005) # 9500\n",
    "    learn.save(path/'mobile_weight_{}.bin'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQkhxgXBPCUt"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHGmWJfb-OQT"
   },
   "outputs": [],
   "source": [
    "test_path = PosixPath('/content/drive/My Drive/DS/yolo/WIDER_test/images')\n",
    "test_data = []\n",
    "for label in os.listdir(test_path):\n",
    "    for file in os.listdir(test_path/label):\n",
    "        test_data.append(label + '/' + file)\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "random.shuffle(test_data)\n",
    "sample_test_data = test_data[:32]\n",
    "sample_test_data = [PIL.Image.open(test_path/x) for x in sample_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FwcyD8mEPD31"
   },
   "outputs": [],
   "source": [
    "sample_test_data = [train_tfms(x) for x in sample_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBELg1PtPI9S"
   },
   "outputs": [],
   "source": [
    "sample_test_data = torch.cat([x[None, ...] for x in sample_test_data], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AwzOVno2Pu76"
   },
   "outputs": [],
   "source": [
    "sample_test_data = sample_test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgWnna2OPcnL"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = learn.model(sample_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F0y9b0MOPqyb"
   },
   "outputs": [],
   "source": [
    "out26 = out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ceBMz3ZqT-nU"
   },
   "outputs": [],
   "source": [
    "boxes = label2box(out26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-bsTrjsUD4x"
   },
   "outputs": [],
   "source": [
    "boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_Fl4rRSUUUo"
   },
   "outputs": [],
   "source": [
    "out26[:, :, CONF, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OaxmWQ91Uhc4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxf4INUmhsRa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ssd_coco.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
